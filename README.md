# **A/B Testing: A Practical Walkthrough with a Simulated Case**

## ðŸ“Œ **Project Overview**
This repository contains an **A/B testing experiment** analyzing the effectiveness of two button designs (`old_design` vs. `new_design`) in an e-commerce setting. The goal is to determine whether the new design increases conversion rates, with a target increase from **3.0% to 4.5%** before deployment.

## ðŸ“Š **Project Workflow**
This project follows a structured approach to A/B testing:
1. **Designing the Experiment** â€“ Defining the hypothesis and methodology.
2. **Collecting & Preparing the Data** â€“ Cleaning and structuring the Kaggle dataset.
3. **Visualizing the Results** â€“ Data exploration and insights.
4. **Testing the Hypothesis** â€“ Statistical significance testing.
5. **Drawing Conclusions** â€“ Final decision-making based on results.
```


## ðŸ“‘ **Dataset Information**
- **Source:** Kaggle ([AB Dataset](https://www.kaggle.com/datasets/tathagatachowdhury09/ab-testing-for-button-color-variants-dataset))
- **Contents:** Includes user interactions with two button designs, split for A/B testing.
- **Size:** ~20,000 observations.

## ðŸ“ˆ **Results & Interpretation**
Key insights and results from the experiment will be documented in `results/ab_test_summary.md`. 

## ðŸ’¡ **How to Contribute**
Want to contribute? Open a pull request or raise an issue!

## ðŸ“œ **License**
This project is licensed under the **MIT License**.
